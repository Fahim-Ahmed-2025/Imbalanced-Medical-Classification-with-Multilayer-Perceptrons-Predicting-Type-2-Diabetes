{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe7c24e",
   "metadata": {},
   "source": [
    "# Imbalanced Medical Classification with MLPs: Predicting Type 2 Diabetes\n",
    "\n",
    "In this tutorial-style notebook, we build a **Multilayer Perceptron (MLP)** to predict whether a person has type 2 diabetes based on clinical and lifestyle features (age, BMI, HbA1c, blood glucose, smoking history, etc.).\n",
    "\n",
    "Our focus is **not just building a neural network**, but understanding how to handle **class imbalance** and how to choose a good **decision threshold** in a medical diagnosis context.\n",
    "\n",
    "Specifically, we will:\n",
    "- Explore the dataset and visualise important relationships.\n",
    "- Show that the diabetes label is **imbalanced** (many more non-diabetic than diabetic cases).\n",
    "- Build a preprocessing pipeline (scaling + one-hot encoding) using `ColumnTransformer` and `Pipeline`.\n",
    "- Train a **baseline MLP** with default threshold 0.5 and discuss why accuracy can be misleading.\n",
    "- Train an **MLP with class weights** to handle imbalance and compare metrics.\n",
    "- Perform **threshold tuning** using precision–recall curves and metric-vs-threshold plots.\n",
    "- Visualise confusion matrices at different thresholds to understand trade-offs.\n",
    "\n",
    "This notebook is meant as a complete, commented example suitable for use as a teaching tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6100085",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dc238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "print('Libraries imported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadf380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes prediction dataset\n",
    "# Make sure the CSV file is in the same directory as this notebook.\n",
    "file_path = 'diabetes_prediction_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd2c5d",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4bd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Class distribution (0 = no diabetes, 1 = diabetes)\n",
    "diabetes_counts = df['diabetes'].value_counts().sort_index()\n",
    "print(diabetes_counts)\n",
    "print('\\nClass proportions:')\n",
    "print((diabetes_counts / len(df)).round(3))\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(x=diabetes_counts.index.astype(str), y=diabetes_counts.values)\n",
    "plt.title('Diabetes Label Distribution')\n",
    "plt.xlabel('Diabetes (0 = no, 1 = yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1897c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Histograms of key numeric features, coloured by diabetes status\n",
    "numeric_cols_to_plot = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "\n",
    "for col in numeric_cols_to_plot:\n",
    "    plt.figure()\n",
    "    sns.histplot(data=df, x=col, hue='diabetes', bins=30, kde=True, stat='density', common_norm=False)\n",
    "    plt.title(f'Distribution of {col} by Diabetes Status')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d67276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Categorical variables vs diabetes\n",
    "plt.figure()\n",
    "sns.countplot(data=df, x='gender', hue='diabetes')\n",
    "plt.title('Gender vs Diabetes')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='smoking_history', hue='diabetes')\n",
    "plt.title('Smoking History vs Diabetes')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e08260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Correlation heatmap for numeric features\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "corr = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap (Numeric Features)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ea6fb",
   "metadata": {},
   "source": [
    "## 3. Preprocessing and Train–Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "target_col = 'diabetes'\n",
    "\n",
    "# We will use all columns except the target as features.\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].astype(int).copy()\n",
    "\n",
    "# Identify categorical and numeric features explicitly\n",
    "categorical_features = ['gender', 'smoking_history']\n",
    "numeric_features = [c for c in feature_cols if c not in categorical_features]\n",
    "\n",
    "print('Numeric features:', numeric_features)\n",
    "print('Categorical features:', categorical_features)\n",
    "\n",
    "# Stratified split to preserve class imbalance structure in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build preprocessing pipeline: scale numeric features, one-hot encode categoricals.\n",
    "# We force OneHotEncoder to return dense arrays to avoid issues with some estimators.\n",
    "\n",
    "try:\n",
    "    cat_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "except TypeError:\n",
    "    # For older versions of scikit-learn that do not support sparse_output\n",
    "    cat_transformer = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, numeric_features),\n",
    "        ('cat', cat_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print('Preprocessing pipeline created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc597ffe",
   "metadata": {},
   "source": [
    "## 4. Baseline MLP (No Class Weighting, Default Threshold 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da91887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first train a simple MLP without any special handling for class imbalance.\n",
    "# This will likely achieve high accuracy (because most patients are non-diabetic),\n",
    "# but may perform poorly on the positive (diabetes=1) class.\n",
    "\n",
    "baseline_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "baseline_model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('mlp', baseline_mlp)\n",
    "])\n",
    "\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "y_proba_baseline = baseline_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_baseline)\n",
    "prec_pos = precision_score(y_test, y_pred_baseline, pos_label=1)\n",
    "rec_pos = recall_score(y_test, y_pred_baseline, pos_label=1)\n",
    "f1_pos = f1_score(y_test, y_pred_baseline, pos_label=1)\n",
    "roc_auc = roc_auc_score(y_test, y_proba_baseline)\n",
    "ap = average_precision_score(y_test, y_proba_baseline)\n",
    "\n",
    "print(f'Baseline MLP Accuracy: {acc:.4f}')\n",
    "print(f'Baseline MLP Precision (positive class): {prec_pos:.4f}')\n",
    "print(f'Baseline MLP Recall (positive class): {rec_pos:.4f}')\n",
    "print(f'Baseline MLP F1 (positive class): {f1_pos:.4f}')\n",
    "print(f'Baseline MLP ROC AUC: {roc_auc:.4f}')\n",
    "print(f'Baseline MLP PR AUC (Average Precision): {ap:.4f}')\n",
    "\n",
    "print('\\nClassification report (Baseline):')\n",
    "print(classification_report(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f53a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_baseline = confusion_matrix(y_test, y_pred_baseline)\n",
    "disp_baseline = ConfusionMatrixDisplay(confusion_matrix=cm_baseline, display_labels=[0, 1])\n",
    "\n",
    "plt.figure()\n",
    "disp_baseline.plot(values_format='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Baseline MLP (Threshold 0.5)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_test, y_proba_baseline)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.title('ROC Curve - Baseline MLP')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall curve\n",
    "precision, recall, pr_thresholds = precision_recall_curve(y_test, y_proba_baseline)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label=f'PR curve (AP = {ap:.3f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - Baseline MLP')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555c52d",
   "metadata": {},
   "source": [
    "## 5. MLP with Class Weights (Handling Imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b96db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give more importance to the minority (diabetes=1) class, we use class_weight='balanced'.\n",
    "# This automatically sets weights inversely proportional to class frequencies.\n",
    "\n",
    "weighted_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=300,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "weighted_model = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('mlp', weighted_mlp)\n",
    "])\n",
    "\n",
    "weighted_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_weighted = weighted_model.predict(X_test)\n",
    "y_proba_weighted = weighted_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_w = accuracy_score(y_test, y_pred_weighted)\n",
    "prec_pos_w = precision_score(y_test, y_pred_weighted, pos_label=1)\n",
    "rec_pos_w = recall_score(y_test, y_pred_weighted, pos_label=1)\n",
    "f1_pos_w = f1_score(y_test, y_pred_weighted, pos_label=1)\n",
    "roc_auc_w = roc_auc_score(y_test, y_proba_weighted)\n",
    "ap_w = average_precision_score(y_test, y_proba_weighted)\n",
    "\n",
    "print(f'Weighted MLP Accuracy: {acc_w:.4f}')\n",
    "print(f'Weighted MLP Precision (positive class): {prec_pos_w:.4f}')\n",
    "print(f'Weighted MLP Recall (positive class): {rec_pos_w:.4f}')\n",
    "print(f'Weighted MLP F1 (positive class): {f1_pos_w:.4f}')\n",
    "print(f'Weighted MLP ROC AUC: {roc_auc_w:.4f}')\n",
    "print(f'Weighted MLP PR AUC (Average Precision): {ap_w:.4f}')\n",
    "\n",
    "print('\\nClassification report (Weighted MLP):')\n",
    "print(classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885dcf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_weighted = confusion_matrix(y_test, y_pred_weighted)\n",
    "disp_weighted = ConfusionMatrixDisplay(confusion_matrix=cm_weighted, display_labels=[0, 1])\n",
    "\n",
    "plt.figure()\n",
    "disp_weighted.plot(values_format='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Weighted MLP (Threshold 0.5)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d92d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare F1 scores for the positive class between baseline and weighted models\n",
    "models = ['Baseline', 'Weighted']\n",
    "f1_scores = [f1_pos, f1_pos_w]\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(x=models, y=f1_scores)\n",
    "plt.title('F1 Score (Positive Class) - Baseline vs Weighted MLP')\n",
    "plt.ylabel('F1 (diabetes=1)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070635a0",
   "metadata": {},
   "source": [
    "## 6. Threshold Tuning for the Weighted MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default decision threshold is 0.5. In medical tasks, we may want to trade precision vs recall.\n",
    "# Here we sweep a range of thresholds and compute precision, recall and F1 for the positive class.\n",
    "\n",
    "thresholds = np.linspace(0.1, 0.9, 17)  # 0.1, 0.15, ..., 0.9\n",
    "prec_list = []\n",
    "rec_list = []\n",
    "f1_list = []\n",
    "\n",
    "for th in thresholds:\n",
    "    y_pred_th = (y_proba_weighted >= th).astype(int)\n",
    "    prec = precision_score(y_test, y_pred_th, pos_label=1, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred_th, pos_label=1, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred_th, pos_label=1, zero_division=0)\n",
    "    prec_list.append(prec)\n",
    "    rec_list.append(rec)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "threshold_df = pd.DataFrame({\n",
    "    'threshold': thresholds,\n",
    "    'precision_pos': prec_list,\n",
    "    'recall_pos': rec_list,\n",
    "    'f1_pos': f1_list\n",
    "})\n",
    "\n",
    "threshold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot precision, recall and F1 as a function of the threshold\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(thresholds, prec_list, marker='o', label='Precision (pos)')\n",
    "plt.plot(thresholds, rec_list, marker='o', label='Recall (pos)')\n",
    "plt.plot(thresholds, f1_list, marker='o', label='F1 (pos)')\n",
    "plt.xlabel('Decision Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall and F1 vs Decision Threshold (Weighted MLP)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e44526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise confusion matrices for three representative thresholds\n",
    "interesting_thresholds = [0.3, 0.5, 0.7]\n",
    "\n",
    "for th in interesting_thresholds:\n",
    "    y_pred_th = (y_proba_weighted >= th).astype(int)\n",
    "    cm_th = confusion_matrix(y_test, y_pred_th)\n",
    "    disp_th = ConfusionMatrixDisplay(confusion_matrix=cm_th, display_labels=[0, 1])\n",
    "    plt.figure()\n",
    "    disp_th.plot(values_format='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - Weighted MLP (Threshold = {th:.2f})')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1866e",
   "metadata": {},
   "source": [
    "## 7. Learning Curve for the Weighted MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To understand how performance scales with more data, we plot a learning curve.\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    weighted_model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring='f1',  # focus on F1 for overall balance\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "train_std = train_scores.std(axis=1)\n",
    "val_mean = val_scores.mean(axis=1)\n",
    "val_std = val_scores.std(axis=1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_sizes, train_mean, marker='o', label='Training F1')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.2)\n",
    "\n",
    "plt.plot(train_sizes, val_mean, marker='o', label='Validation F1')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.2)\n",
    "\n",
    "plt.title('Learning Curve - Weighted MLP (F1 Score)')\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('F1 score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3b98e",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "In this notebook we:\n",
    "- Confirmed that the diabetes label is **highly imbalanced**, with far fewer positive cases.\n",
    "- Built a preprocessing pipeline for numeric and categorical features.\n",
    "- Trained a **baseline MLP** and showed that accuracy alone hides poor recall on the positive class.\n",
    "- Trained an **MLP with class weights**, improving recall and F1 for diabetic patients.\n",
    "- Used **ROC and precision–recall curves** to evaluate the classifier beyond accuracy.\n",
    "- Performed **threshold tuning** and visualised how precision, recall and F1 change with the decision threshold.\n",
    "- Plotted confusion matrices at different thresholds to make the trade-offs concrete.\n",
    "- Added a **learning curve** to see how performance scales with additional training data.\n",
    "\n",
    "This demonstrates how Multilayer Perceptrons can be applied responsibly to imbalanced medical classification problems, with an emphasis on evaluation, threshold selection and fairness to the minority (positive) class."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
